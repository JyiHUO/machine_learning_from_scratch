{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 什么是CCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "典型关联分析(Canonical Correlation Analysis，以下简称CCA)是最常用的挖掘数据关联关系的算法之一。比如我们拿到两组数据，第一组是人身高和体重的数据，第二组是对应的跑步能力和跳远能力的数据。那么我们能不能说这两组数据是相关的呢？CCA可以帮助我们分析这个问题。将数据形式不同的矩阵映射成向量，从而可以比较他们之间的相关系数。多用在信息的检索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCA推导"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先我们有两份数据$X (N, C1)$ 和 $Y (N, C2)$，注意我们的数据要先进行标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用权重$a(C1, 1)$和$b(C2, 1)$对$X$和$Y$做线性变化$X' = Xa$，$Y' = Yb$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算得到我们的相关系数，并且要最大化我们的相关系数，问题可描述成："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\underset{a, b}{\\operatorname{argmax}} \\frac{cov(X', Y')}{\\sqrt{Var(X')} \\sqrt{Var(Y')}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进行展开，注意X和Y的均值为0：\n",
    "$$\n",
    "cov(X', Y') = E[[Xa - E(Xa)]^T [Yb - E(Yb)]] = E[a^TX^TYb] = a^TE[X^TY]b\n",
    "$$\n",
    "\n",
    "$$\n",
    "Var(X') = Var(Xa) = a^TE[X^TX]a\n",
    "$$\n",
    "\n",
    "$$\n",
    "Var(Y') = Var(Ya) = b^TE[Y^TY]b\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代入原式子可化成："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\underset{a, b}{\\operatorname{argmax}} \\frac{a^TE[X^TY]b}{\\sqrt{a^TE[X^TX]a} \\sqrt{b^TE[Y^TY]b}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于这个最优化问题，我们发现a和b增大相同的倍数最优化的值不改变，所以我们需要应用svm的技巧，固定分母，只优化分子，原问题可变成："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\underset{a, b}{\\operatorname{argmax}} a^TE[X^TY]b\n",
    "$$\n",
    "\n",
    "$$\n",
    "s.t. \\quad a^TE[X^TX]a = 1 \\quad b^TE[Y^TY]b = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用小技巧来把数学期望转成协方差矩阵，方便我们的计算："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "E(X^T Y) = E(X^T Y) - E(X)E(Y) = cov(X, Y) = S_{xy}\n",
    "$$\n",
    "\n",
    "$$\n",
    "E(X^T X) = E(X^T X) - E(X)E(X) = cov(X, X) = S_{xx}\n",
    "$$\n",
    "\n",
    "$$\n",
    "E(Y^T Y) = E(Y^T Y) - E(Y)E(Y) = cov(Y, Y) = S_{yy}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代入后:\n",
    "\n",
    "$$\n",
    "\\underset{a, b}{\\operatorname{argmax}} a^TS_{xy}b\n",
    "$$\n",
    "\n",
    "$$\n",
    "s.t. \\quad a^TS_{xx}a = 1 \\quad b^TS_{yy}b = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们仔细观察后，发现可以再用一个更大的trick，令$a = S_{xx}^{-\\frac{1}{2}} u$ 和$b = S_{yy}^{-\\frac{1}{2}}v$，其中u(C1, 1),v(C2, 1)那么原式子可变成：\n",
    "\n",
    "$$\n",
    "\\underset{a, b}{\\operatorname{argmax}} u^T S_{xx}^{-\\frac{1}{2}T} S_{xy} S_{yy}^{-\\frac{1}{2}}v\n",
    "$$\n",
    "\n",
    "$$\n",
    "s.t. \\quad u^Tu = 1 \\quad v^Tv = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个时候你发现中间那三个S是不是可以用SVD，没错是的，你的直觉很准确，就是要使用SVD来把三个S变成另外三个矩阵："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "S_{xx}^{-\\frac{1}{2}T} S_{xy} S_{yy}^{-\\frac{1}{2}} = U \\sum V\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中$U^TU = I$和$VV^T = I$，U的每一列都是标准正交基，V的每一行都是标准正交基，也就是说U里面的每一列只有它自己的內积为1其他为0，接下来我们自己观察下面这个式子："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\underset{a, b}{\\operatorname{argmax}} u^T U \\sum Vv\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这里u是基向量，U里面的每一列都是基向量（而且相互正交），在这里我直接给出我的直觉，后面复习完线性代数再证明吧：U里面只有一个列向量跟u的内积为1其他的内积为0。所以u^TU是一个one-hot向量（v也是同样的意思）。所以该问题变成找到$\\sum$最大的特征值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCA算法流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入：X和Y数据(N,C)的形式\n",
    "\n",
    "输出：权重a和b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对输出的数据进行标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算X的方差$S_{xx}$，计算y的方差$S_{yy}$，计算X与Y的协方差$S_{xy}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用svd求到: $S_{xx}^{-\\frac{1}{2}T} S_{xy} S_{yy}^{-\\frac{1}{2}} = U \\sum V$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "找到最大特征值和对应的特征向量u和v，并计算出a和b：$a = S_{xx}^{-\\frac{1}{2}} u$ 和$b = S_{yy}^{-\\frac{1}{2}}v$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCA代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CCA:\n",
    "    def __init__(self):\n",
    "        self.a = None\n",
    "        self.b = None\n",
    "    \n",
    "    def train(self, X, Y):\n",
    "        Nx, cx = X.shape\n",
    "        Ny, cy = Y.shape\n",
    "        \n",
    "        # 标准化 (N, C)\n",
    "        X = (X - np.mean(X, 0)) / np.std(X, 0)\n",
    "        Y = (Y - np.mean(Y, 0)) / np.std(Y, 0)\n",
    "        \n",
    "        # 求三个S\n",
    "        data = np.concatenate([X, Y], axis = 1)\n",
    "        cov = np.cov(data, rowvar=False)\n",
    "        N, C = cov.shape\n",
    "        Sxx = cov[0:cx, 0:cx]\n",
    "        Syy = cov[cy:C, cy:C]\n",
    "        Sxy = cov[0:cx, cy:C]\n",
    "        Sxx_ = linalg.sqrtm(np.linalg.inv(Sxx))\n",
    "        Syy_ = linalg.sqrtm(np.linalg.inv(Syy))\n",
    "        M = Sxx_.T.dot(Sxy.dot(Syy_))\n",
    "        U, S, V = np.linalg.svd(M)\n",
    "        u = U[:, 0]\n",
    "        v = V[0, :]\n",
    "        self.a = Sxx_.dot(u)\n",
    "        self.b = Syy_.dot(v)\n",
    "        \n",
    "    def predict(self, X, Y):\n",
    "        X_ = X.dot(self.a)\n",
    "        Y_ = Y.dot(self.b)\n",
    "        return X_, Y_\n",
    "    \n",
    "    def cal_corrcoef(self, X, Y):\n",
    "        X_, Y_ = self.predict(X, Y)\n",
    "        return np.corrcoef(X_, Y_)[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "n = 500\n",
    "# 2 latents vars:\n",
    "l1 = np.random.normal(size=n)\n",
    "l2 = np.random.normal(size=n)\n",
    "\n",
    "latents = np.array([l1, l1, l2, l2]).T\n",
    "X = latents + np.random.normal(size=4 * n).reshape((n, 4))\n",
    "Y = latents + np.random.normal(size=4 * n).reshape((n, 4))\n",
    "\n",
    "X_train = X[:n // 2]\n",
    "Y_train = Y[:n // 2]\n",
    "X_test = X[n // 2:]\n",
    "Y_test = Y[n // 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 4)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my cca\n",
    "clf = CCA()\n",
    "clf.train(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7200173442101319\n",
      "0.671638992091987\n"
     ]
    }
   ],
   "source": [
    "print (clf.cal_corrcoef(X_train, Y_train))\n",
    "print (clf.cal_corrcoef(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7202109376634042\n",
      "0.6719982185448227\n"
     ]
    }
   ],
   "source": [
    "# compare with sklearn\n",
    "from sklearn.cross_decomposition import CCA\n",
    "cca_sklearn = CCA(n_components=1)\n",
    "cca_sklearn.fit(X_train, Y_train)\n",
    "X_c, Y_c = cca_sklearn.transform(X_train, Y_train)\n",
    "X_c_, Y_c_ = cca_sklearn.transform(X_test, Y_test)\n",
    "print (np.corrcoef(X_c[:,0], Y_c[:, 0])[0,1])\n",
    "print (np.corrcoef(X_c_[:, 0], Y_c_[:, 0])[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完美：精读差别不大"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCA缺点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要计算svd，逆矩阵还有平方根矩阵，非常耗时，只能处理线性的情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[link](http://www.cnblogs.com/pinard/p/6288716.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
